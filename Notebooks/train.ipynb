{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos = torch.arange(x.shape[0], dtype=torch.float32, device=x.device).unsqueeze(1)\n",
    "        return self.linear(pos)\n",
    "\n",
    "# Temporal Encoding\n",
    "class TemporalEncoding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, d_model)\n",
    "\n",
    "    def forward(self, time_steps):\n",
    "        return self.linear(time_steps.unsqueeze(1).float())\n",
    "\n",
    "# Custom GNN Layer\n",
    "class CustomGNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_in_chanel=5):\n",
    "        super().__init__(aggr='mean')\n",
    "        self.node_fc = nn.Linear(in_channels, out_channels)\n",
    "        self.edge_fc = nn.Linear(edge_in_chanel, out_channels)\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.node_fc(x)\n",
    "        edge_attr = self.edge_fc(edge_attr)\n",
    "        return self.norm(self.propagate(edge_index, x=x, edge_attr=edge_attr))\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return x_j + edge_attr\n",
    "\n",
    "# Transformer Layer\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=in_dim, num_heads=4, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = x.unsqueeze(1)  \n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        return self.norm(attn_output.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN + GRU Model\n",
    "class GNN_GRU_Model(nn.Module):\n",
    "    \"\"\"\n",
    "GNN-GRU Model for  Graph-Based Travel Time Prediction\n",
    "\n",
    "This script defines a neural network architecture combining Graph Neural Networks (GNNs),\n",
    "Transformers, and Gated Recurrent Units (GRUs) for predicting travel time in  graphs.\n",
    "The model captures both spatial and temporal dependencies using the following components:\n",
    "\n",
    "1. **PositionalEncoding**: Encodes node positions in the input sequence.\n",
    "2. **TemporalEncoding**: Captures time-dependent features using a linear transformation.\n",
    "3. **CustomGNNLayer**: A message-passing GNN layer that processes node and edge features.\n",
    "4. **TransformerLayer**: Applies self-attention to enhance feature representation.\n",
    "5. **GNN_GRU_Model**: The main architecture combining GNNs, Transformers, and GRUs.\n",
    "6. **train_model**: Implements the training loop with MSE loss and Adam optimizer.\n",
    "\n",
    "### Workflow:\n",
    "- Load or generate graph snapshots containing node and edge features.\n",
    "- Train the GNN-GRU model using past time-step snapshots.\n",
    "- Predict travel time for the next time steps.\n",
    "- Evaluate performance using Mean Squared Error (MSE).\n",
    "\n",
    "### Inputs:\n",
    "- **Node features**: Temporal and spatial attributes per node.\n",
    "- **Edge features**: Graph connectivity and relationships between nodes.\n",
    "- **Time-step sequences**: Past snapshots for temporal modeling.\n",
    "\n",
    "### Outputs:\n",
    "- **Predicted travel time** for each edge at the next time step.\n",
    "\n",
    "This model is optimized for real-world traffic prediction tasks, where  graphs\n",
    "capture evolving traffic conditions and vehicle movements over time.\n",
    "\"\"\"\n",
    "\n",
    "    def __init__(self, node_feat_dim, edge_feat_dim, hidden_dim, output_dim, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.pos_enc = PositionalEncoding(hidden_dim)\n",
    "        self.temp_enc = TemporalEncoding(hidden_dim)\n",
    "        self.gnn_layers = nn.ModuleList([CustomGNNLayer(hidden_dim, hidden_dim, edge_feat_dim) for _ in range(num_layers)])\n",
    "        self.transformer = TransformerLayer(hidden_dim, hidden_dim)\n",
    "        self.gru = nn.GRU(hidden_dim, edge_feat_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(edge_feat_dim, output_dim)\n",
    "\n",
    "    def forward(self, x_seq, edge_index, edge_attr_seq, time_steps_seq):\n",
    "        num_nodes = x_seq.shape[1]  \n",
    "        past_steps = x_seq.shape[0]  \n",
    "\n",
    "        x_out = []\n",
    "        for t in range(past_steps):\n",
    "            x_t = self.pos_enc(x_seq[t]) + self.temp_enc(time_steps_seq[t])  \n",
    "            for gnn in self.gnn_layers:\n",
    "                x_t = gnn(x_t, edge_index, edge_attr_seq[t])  \n",
    "            x_out.append(x_t)\n",
    "\n",
    "        x_out = torch.stack(x_out, dim=1)  \n",
    "        \n",
    "        x_out, _ = self.gru(x_out)  \n",
    "\n",
    "        return self.fc_out(x_out[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Graph Generation\n",
    "def generate_sample_graphs(num_snapshots, num_nodes, node_feat_dim, edge_feat_dim , past_steps=12):\n",
    "    graphs = []\n",
    "    all_x = torch.randn(num_snapshots, num_nodes, node_feat_dim)\n",
    "    all_edge_attr = torch.randn(num_snapshots, num_nodes * 2, edge_feat_dim)\n",
    "    all_time_steps = torch.randint(0, 24, (num_snapshots, num_nodes))\n",
    "\n",
    "    for i in range(num_snapshots - past_steps):\n",
    "        x_seq = all_x[i:i + past_steps]  # (past_steps, num_nodes, node_feat_dim)\n",
    "        edge_attr_seq = all_edge_attr[i:i + past_steps]  # (past_steps, num_edges, edge_feat_dim)\n",
    "        time_seq = all_time_steps[i:i + past_steps]  # (past_steps, num_nodes)\n",
    "        edge_index = torch.randint(0, num_nodes, (2, num_nodes * 2))  # Static edge index\n",
    "        graphs.append((x_seq, edge_index, edge_attr_seq, time_seq))\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate_model(model, graphs, save_path, details):\n",
    "    \"\"\"\n",
    "    Evaluates the given model on the provided graph snapshots.\n",
    "    \n",
    "    For each graph snapshot in 'graphs', the model's output is compared with the corresponding\n",
    "    target loaded from the file. The function computes both the Mean Squared Error (MSE) and \n",
    "    the Mean Absolute Error (MAE) across all graph snapshots, and then prints the average losses.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained model to evaluate.\n",
    "        graphs (list): A list of tuples, where each tuple contains \n",
    "                       (x, edge_index, edge_attr, time_steps) for a graph snapshot.\n",
    "                       \n",
    "    Returns:\n",
    "        None. Prints the average MSE and MAE losses.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Load targets and select the evaluation portion\n",
    "    targets = torch.load(\"../train_data/rio_data/rio_data_target.pth\")\n",
    "    targets = targets[3010:]\n",
    "    \n",
    "    mse_loss_total = 0.0\n",
    "    mae_loss_total = 0.0\n",
    "    criterion_mse = nn.MSELoss()\n",
    "    criterion_mae = nn.L1Loss()  # L1 loss corresponds to MAE\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, edge_index, edge_attr, time_steps) in enumerate(graphs):\n",
    "            output = model(x, edge_index, edge_attr, time_steps)\n",
    "            target = targets[i]\n",
    "            mse_loss = criterion_mse(output, target)\n",
    "            mae_loss = criterion_mae(output, target)\n",
    "            mse_loss_total += mse_loss.item()\n",
    "            mae_loss_total += mae_loss.item()\n",
    "            \n",
    "        avg_mse_loss = mse_loss_total / len(graphs)\n",
    "        avg_mae_loss = mae_loss_total / len(graphs)\n",
    "        print(f\"Evaluation MSE Loss: {avg_mse_loss:.4f}, MAE Loss: {avg_mae_loss:.4f}\")\n",
    "        with open(save_path, \"a\") as f:\n",
    "            f.write(f\"Evaluation Results {details}\\n\")\n",
    "            f.write(f\"MSE Loss: {avg_mse_loss:.4f}\\n\")\n",
    "            f.write(f\"MAE Loss: {avg_mae_loss:.4f}\\n\")\n",
    "            f.write(\"=\" * 30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_9588\\3866800218.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sample_graphs = loaded_tensor = torch.load(\"../train_data/rio_data/rio_data.pth\")\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_9588\\930152928.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  targets = torch.load(\"../train_data/rio_data/rio_data_target.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation MSE Loss: 2871.0100, MAE Loss: 15.2254\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "def train_model(model, graphs, epochs=10, lr=0.001):\n",
    "    \"\"\"\n",
    "    Trains a spatiotemporal graph-based model using a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : torch.nn.Module\n",
    "        The neural network model to be trained.\n",
    "    graphs : iterable\n",
    "        An iterable containing graph data tuples (x_seq, edge_index, edge_attr_seq, time_steps_seq),\n",
    "        where:\n",
    "        - x_seq : Tensor representing node features over time.\n",
    "        - edge_index : Tensor defining graph connectivity.\n",
    "        - edge_attr_seq : Tensor representing edge features over time.\n",
    "        - time_steps_seq : Tensor representing the temporal sequence.\n",
    "    epochs : int, optional (default=10)\n",
    "        The number of training epochs.\n",
    "    lr : float, optional (default=0.001)\n",
    "        Learning rate for the Adam optimizer.\n",
    "\n",
    "    Training Process:\n",
    "    -----------------\n",
    "    - Uses Mean Squared Error (MSE) loss function.\n",
    "    - Performs forward pass, computes loss, backpropagates gradients, and updates model weights.\n",
    "    - Iterates through the dataset, training the model on each graph sample.\n",
    "\n",
    "    Prints:\n",
    "    -------\n",
    "    - The average loss per epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    targets = torch.load(\"../train_data/rio_data/rio_data_target.pth\")\n",
    "    targets = targets[:3010]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        i = 0\n",
    "        for x_seq, edge_index, edge_attr_seq, time_steps_seq in graphs:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_seq, edge_index, edge_attr_seq, time_steps_seq)\n",
    "            target = targets[i]\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            i+=1\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(graphs):.4f}\")\n",
    "        # print(target)\n",
    "\n",
    "\n",
    "\n",
    "num_snapshots = 4300\n",
    "num_nodes = 196\n",
    "node_feat_dim = 8\n",
    "edge_feat_dim = 2\n",
    "hidden_dim = 16\n",
    "output_dim = 12  # Predict next 12 time steps\n",
    "batch_size = 32\n",
    "\n",
    "sample_graphs = loaded_tensor = torch.load(\"../train_data/rio_data/rio_data.pth\")\n",
    "train = sample_graphs[:3010]\n",
    "test = sample_graphs[3010:]\n",
    "# sample_graphs = generate_sample_graphs(num_snapshots, num_nodes, node_feat_dim, edge_feat_dim)\n",
    "model = GNN_GRU_Model(node_feat_dim, edge_feat_dim, hidden_dim, output_dim)\n",
    "train_model(model, train,10)\n",
    "evaluate_model(model, test, save_path='../train_results/rio/evaluation.txt', details='10 epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
